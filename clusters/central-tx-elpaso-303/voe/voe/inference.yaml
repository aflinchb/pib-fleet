apiVersion: apps/v1
kind: Deployment
metadata:
  name: inferencemodule
  namespace: voe
  labels:
    app.kubernetes.io/name: inferencemodule
    app.kubernetes.io/managed-by: kubectl
spec:
  replicas: 1
  selector:
    matchLabels:
      app: inferencemodule
  minReadySeconds: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  template:
    metadata:
      labels:
        app: inferencemodule
      annotations:
        gitops.version: v-22-06-20-17-12-38
    spec:
      nodeSelector:
        "beta.kubernetes.io/os": linux
      containers:
      - name: inferencemodule
        image: ghcr.io/retaildevcrews/voeapp/inference:beta
        imagePullPolicy: Always
        ports:
        - containerPort: 5000
        livenessProbe:
          httpGet:
            path: /healthz
            port: 5000
          initialDelaySeconds: 10
          periodSeconds: 60
        readinessProbe:
          httpGet:
            path: /readyz
            port: 5000
          initialDelaySeconds: 10
          periodSeconds: 60
          failureThreshold: 3
        resources:
          requests:
            cpu: 2000m
            memory: 400Mi
          limits:
            cpu: 3000m
            memory: 1500Mi
        env:
          - name: IOTHUB_CONNECTION_STRING
            valueFrom:
              secretKeyRef:
                name: azure-env
                key: IOTHUB_CONNECTION_STRING
          - name: IOTEDGE_DEVICE_CONNECTION_STRING
            valueFrom:
              secretKeyRef:
                name: azure-env
                key: IOTEDGE_DEVICE_CONNECTION_STRING
          - name: IS_OPENCV
            value: "true"
          - name: IS_K8S
            value: "true"

---
apiVersion: v1
kind: Service
metadata:
  name: inferencemodule
  namespace: voe
  labels:
    app.kubernetes.io/name: inferencemodule
    app.kubernetes.io/managed-by: kubectl
spec:
  ports:
  - port: 5000
  selector:
    app: inferencemodule
